Recommended Structure:
cpp
Copy
Edit
A:\OPENAI\
‚îÇ
‚îî‚îÄ‚îÄ‚îÄComfyUI\
    ‚îÇ   main.py
    ‚îÇ   requirements.txt
    ‚îî‚îÄ‚îÄ‚îÄcomfyenv\     ‚Üê your virtual environment lives here
    ‚îî‚îÄ‚îÄ‚îÄcustom_nodes\
	
	
1. Install Python (3.10 or 3.11 recommended) From: https://www.python.org/downloads/

2. Clone ComfyUI & Install Dependencies-
git clone https://github.com/comfyanonymous/ComfyUI.git
cd ComfyUI

cd ComfyUI/custom_nodes
git clone https://github.com/comfyanonymous/ComfyUI-VideoHelperExtension.git


3. Setup a Virtual Environment
python -m venv comfyenv
.\comfyenv\Scripts\activate
pip install -r requirements.txt
deactivate - EXIT OUT ON ENV


4. Install AnimateDiff Node - Type :   cd ..   # to move 1 step back in a directory but stay in env only and ove to below floder
Clone into the custom_nodes folder:
cd ComfyUI/custom_nodes
git clone https://github.com/Animator-Anon/ComfyUI-AnimateDiff-Evolved
or 
cd A:\OPENAI\ComfyUI\custom_nodes
git clone https://github.com/cubiq/ComfyUI-AnimateDiff-Evolved
or
git clone https://github.com/Kosinkadink/ComfyUI-AnimateDiff-Evolved.git - this one seems to be working 

cd ComfyUI-AnimateDiff-Evolved
pip install -r requirements.txt

After pulling clone, Close the running ComfyUI window
Just press Ctrl + C in the terminal window where it's running.

5.Download AnimateDiff Model (v3.1 Recommended)=v3_sd15_mm.ckpt
Place the .ckpt file into:
ComfyUI/models/animatediff_models

 Final Result Should Look Like:
A:\OPENAI\ComfyUI\
‚îî‚îÄ‚îÄ custom_nodes\
    ‚îî‚îÄ‚îÄ ComfyUI-AnimateDiff-Evolved\
        ‚îî‚îÄ‚îÄ models\
            ‚îî‚îÄ‚îÄ motion_modules\
                ‚îî‚îÄ‚îÄ v3_sd15_mm.ckpt

6. Download Stable Diffusion Model (Base for Animation)= Realistic Vision V5.1 , realisticVisionV60B1_v51HyperVAE.safetensors
ComfyUI/models/checkpoints/

A:\OPENAI\ComfyUI\
‚îî‚îÄ‚îÄ models\
    ‚îî‚îÄ‚îÄ checkpoints\
        ‚îî‚îÄ‚îÄ realisticVisionV60B1_v51HyperVAE.safetensors

optional - ComfyUI/models/vae/vae-ft-mse-840000-ema-pruned.safetensors # Create the vae/ folder if it doesn‚Äôt exist.
If your workflow doesn‚Äôt specify a VAE, ComfyUI may use the default or skip it ‚Äî so explicitly adding the node is best.

How to Install ComfyUI Manager (Node Manager)
Go to your custom_nodes directory:
ComfyUI/custom_nodes/
git clone https://github.com/ltdrdata/ComfyUI-Manager.git


7.Build the ComfyUI Workflow (Node-Based)
üîÑ Workflow Steps
Prompt Generator (Text input)
AnimateDiff Loader Node
Sampler (KSampler or Euler)
Checkpoint Loader (SD model)
Conditioning + Latent Input
AnimateDiff video frame node
VAE Decoder
Save Image / Save MP4 node

8.Place the workflow in ComfyUI/workflows/
 and go to directory with main.py file and run in terinal 
 if there is error for CUDA assertion -  AssertionError: Torch not compiled with CUDA enabled
pip uninstall torch torchvision torchaudio -y
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
or
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
run below-
import torch
print(torch.cuda.is_available())  # Should return True , 
9.rerun main.py file 

once run go to http://127.0.0.1:8188


---------------------------------------------------


The latest versions of ComfyUI (after May 2024) require each node in the JSON to include:

‚úÖ Mandatory Fields per Node:
mode

order

flags

properties

inputs as an array

outputs as an array



Quick Start
Note: AnimateDiff is also offically supported by Diffusers. Visit AnimateDiff Diffusers Tutorial for more details. Following instructions is for working with this repository.

Note: For all scripts, checkpoint downloading will be automatically handled, so the script running may take longer time when first executed.

1. Setup repository and environment
git clone https://github.com/guoyww/AnimateDiff.git
cd AnimateDiff

pip install -r requirements.txt
2. Launch the sampling script!
The generated samples can be found in samples/ folder.

2.1 Generate animations with comunity models
python -m scripts.animate --config configs/prompts/1_animate/1_1_animate_RealisticVision.yaml
python -m scripts.animate --config configs/prompts/1_animate/1_2_animate_FilmVelvia.yaml
python -m scripts.animate --config configs/prompts/1_animate/1_3_animate_ToonYou.yaml
python -m scripts.animate --config configs/prompts/1_animate/1_4_animate_MajicMix.yaml
python -m scripts.animate --config configs/prompts/1_animate/1_5_animate_RcnzCartoon.yaml
python -m scripts.animate --config configs/prompts/1_animate/1_6_animate_Lyriel.yaml
python -m scripts.animate --config configs/prompts/1_animate/1_7_animate_Tusun.yaml
2.2 Generate animation with MotionLoRA control
python -m scripts.animate --config configs/prompts/2_motionlora/2_motionlora_RealisticVision.yaml
2.3 More control with SparseCtrl RGB and sketch
python -m scripts.animate --config configs/prompts/3_sparsectrl/3_1_sparsectrl_i2v.yaml
python -m scripts.animate --config configs/prompts/3_sparsectrl/3_2_sparsectrl_rgb_RealisticVision.yaml
python -m scripts.animate --config configs/prompts/3_sparsectrl/3_3_sparsectrl_sketch_RealisticVision.yaml
2.4 Gradio app
We created a Gradio demo to make AnimateDiff easier to use. By default, the demo will run at localhost:7860.

python -u app.py
